# OKR Framework

## Introduction

This framework helps you create and manage Objectives and Key Results (OKRs) that align teams around measurable outcomes. OKRs operationalize strategy into actionable, measurable goals that connect daily work to business results.

**When to use OKRs:**
- Operationalizing strategic priorities into measurable outcomes
- Aligning teams around shared objectives
- Tracking progress on key initiatives
- Connecting product work to business metrics

**When OKRs might not be needed:**
- Very small teams (<5 people) where alignment is already strong
- Exploratory research phases before clear objectives emerge
- One-off projects with clear, single success criteria

## How to Use This Framework

1. **Set Objectives**: Align with strategic priorities (1-2 per team)
2. **Define Key Results**: Create measurable outcomes (2-4 per objective)
3. **Track Weekly**: Update confidence and progress
4. **Review Quarterly**: Grade results and set next cycle
5. **Link to Work**: Connect PRDs and initiatives to KR IDs

## How to Maintain

- **Weekly Reviews**: Update confidence (0/1/2) and track progress
- **Mid-Cycle**: Assess if objectives need adjustment
- **End of Cycle**: Grade KRs (0.0-1.0) and set next cycle
- **Quarterly**: Archive completed OKRs and document learnings

## Principles
- Outcome over output: tie to business results and job outcomes.
- Evidence before investment: RAT-style KRs with thresholds.
- Small docs, fast loops: 1–2 pages; weekly confidence checks.
- Traceability: link OKRs to JTBD → Opportunity → RAT → PRD → Decision Log.

## Inputs (each cycle)
- Company/BU priorities and constraints.
- Team mission and core metrics (SLAs, latency, cost-to-serve).
- Opportunity backlog tied to JTBD and ODI outcomes.
- Last cycle’s decision log and post-mortems.

## OKR Types
- Impact OKRs: move a core business metric.
- Enabler OKRs: unlock future impact (platform, data quality, compliance).
Keep 1–2 Objectives per team; 2–4 KRs per Objective.

## KR Quality
- Specific, measurable, time-bound; mix lagging/leading.
- Instrumented with event/ID definitions and pass/fail thresholds.
- Avoid milestone/project KRs; use outcome proxies when needed.

## Process (2-week spin-up; rolling thereafter)
1) Prep (async): compile inputs; propose problem spaces and candidate metrics.
2) Framing workshop: align on “why now,” pick 1–2 Objectives, brainstorm KRs.
3) Convert top assumptions into RAT-style KRs with thresholds.
4) Stakeholder review: validate metrics, guardrails, dependencies.
5) Publish to company OKRs; assign owners; link dashboards.

## Cadence
- Weekly 20–30 min: KR status, confidence (0/1/2), risks, next RAT test.
- Mid-cycle: decide to double-down, pivot, or stop; snapshot if materially changed.
- End-cycle: grade KRs (0.0–1.0); roll learnings into decision log.

## Scoring & Confidence
- Scoring at cycle end: 0.0–1.0 per KR; average → Objective score.
- Weekly confidence: 0 (off-track), 1 (at-risk), 2 (on-track); cite evidence.

## Linking Rules
- Assign stable KR IDs `O#-KR#`. Use everywhere (initiatives, PRDs, dashboards).
- Initiatives list KR IDs they contribute to and link evidence; do not duplicate metrics.
- Material changes recorded in `decision-log.md`; archive snapshots on change.

## Example Objectives (illustrative)
- Reduce time-to-signal from insight to product changes by 30%.
- Improve post-release operational reliability.
- Strengthen governance and compliance for key product decisions.

## References
- Templates: `./2.2.2-okr-template.md`
- Company Context: `../../01-Company-Context/README.md`
- Product Strategy: `../2.1-Product-Strategy/`
- Roadmap: `../2.3-Roadmap/`


